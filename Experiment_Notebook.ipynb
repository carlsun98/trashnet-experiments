{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of trash5(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L3YsNKfrFLo",
        "colab_type": "text"
      },
      "source": [
        "# **DO NOT HARDCODE NUMBERS or LINKS**\n",
        "Add any number/link/constant to parameter list below. If see any hardcode number move it to parameter list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8uCZ07Qt0WN",
        "colab_type": "text"
      },
      "source": [
        "Dataset Google drive folder: https://drive.google.com/open?id=1HXG9ojRsfo8X9w6w4LbfjPJKxJF3UinW\n",
        "(80% training, 20% testing)\n",
        "\n",
        "Keeping track of net evolution and attempts Google doc: https://docs.google.com/document/d/19fguUEgDDC_anrR7M10gv2EteymBbQM-lQrwZ94wabs/edit?usp=sharing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOEvcrjjqyml",
        "colab_type": "text"
      },
      "source": [
        "# **TODO/CONCERNS**\n",
        "\n",
        "\n",
        "1.   Implement a better network architecture (now it's just 2 conv, 3 fully connected layers with random nodes for each layer).\n",
        "2.   If cannot improve the network with 6 category, pick 1 category and clumps the other ones together so it's a binary sorting (ie. metal vs everything, or glass vs everything, etc). \n",
        "3.   (For future) Figure out how to save the net so when we get to a good architecture we can keep using it instead of training it over and over again\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zNWFXZWSj4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpqbqQiJTbAg",
        "colab_type": "code",
        "outputId": "f8ea319a-d44c-463f-d036-b74d8e79117d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRCodkl6jqLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMETER LIST\n",
        "trainRootDir = \"/content/gdrive/My Drive/trash5/train\"\n",
        "testRootDir = \"/content/gdrive/My Drive/trash5/test\"\n",
        "train2RootDir = \"/content/gdrive/My Drive/trash5/train2\"\n",
        "\n",
        "imageCropSize = 32\n",
        "\n",
        "trainBatchNum = 32\n",
        "testBatchNum = 100\n",
        "\n",
        "epochNum = 50\n",
        "learnRate = 0.005\n",
        "momentumNum = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnfVa_mzW-ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "data_transform_augmented = transforms.Compose([\n",
        "                                    transforms.RandomApply([transforms.RandomVerticalFlip(),\n",
        "                                                            transforms.RandomHorizontalFlip(),\n",
        "                                                            transforms.RandomGrayscale(),]),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmdL0b5KXdzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training data\n",
        "train_datasets = torchvision.datasets.ImageFolder(root = trainRootDir, transform = data_transforms)\n",
        "train_datasets_aug = torchvision.datasets.ImageFolder(root = train2RootDir, transform = data_transform_augmented)\n",
        "trainloader = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([train_datasets, train_datasets_aug]), \n",
        "                                          batch_size = trainBatchNum, \n",
        "                                          shuffle = True, num_workers = 2)\n",
        "# trainloader = torch.utils.data.DataLoader(train_datasets, batch_size = trainBatchNum, shuffle = True, num_workers = 2)\n",
        "\n",
        "# Validation data\n",
        "# valid_datasets = torchvision.datasets.ImageFolder(root = validRootDir, transform = data_transforms)\n",
        "# validloader = torch.utils.data.DataLoader(valid_datasets, batch_size = trainBatchNum, shuffle = True, num_workers = 2)\n",
        "\n",
        "# Testing data\n",
        "test_datasets = torchvision.datasets.ImageFolder(root= testRootDir, transform = data_transforms)\n",
        "testloader = torch.utils.data.DataLoader(test_datasets, batch_size = testBatchNum, shuffle = False, num_workers = 2)\n",
        "\n",
        "# Class label equivalence\n",
        "classes = ('glass', 'paper', 'cardboard', 'plastic', 'metal', 'trash')\n",
        "\n",
        "# data_loaders = {\"train\": trainloader, \"val\": validloader}\n",
        "# data_lengths = {\"train\": len(train_datasets), \"val\": len(valid_datasets)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thJQ-nBubeuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Define the network\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "#         self.fc1 = nn.Linear(16 * 93 * 125, 120)\n",
        "#         self.fc2 = nn.Linear(120, 84)\n",
        "#         self.fc3 = nn.Linear(84, 6)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.conv1(x)))\n",
        "#         x = self.pool(F.relu(self.conv2(x)))\n",
        "#         x = x.view(-1, 16 * 93 * 125)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.fc3(x)\n",
        "#         return x\n",
        "\n",
        "# network = Net()\n",
        "\n",
        "\n",
        "\n",
        "scale = 0.0625\n",
        "# Define the network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, math.floor(96 * scale), (11, 265), stride = 4, padding = 2)\n",
        "        self.pool = nn.MaxPool2d(3, stride = 2, padding = 0)\n",
        "        self.conv2 = nn.Conv2d(math.floor(96 * scale), math.floor(256 * scale), 5, stride = 1, padding = 2)\n",
        "        self.conv3 = nn.Conv2d(math.floor(256 * scale), math.floor(384 * scale), 3, stride = 1, padding = 1)\n",
        "        self.conv4 = nn.Conv2d(math.floor(384 * scale), math.floor(384 * scale), 3, stride = 1, padding = 1)\n",
        "        self.conv5 = nn.Conv2d(math.floor(384 * scale), math.floor(256 * scale), 3, stride = 1, padding = 1)\n",
        "        self.drop = nn.Dropout(p = 0.5)\n",
        "        self.thresh = nn.Threshold(0, 1e-6)\n",
        "        self.fc1 = nn.Linear(math.floor(256 * scale) * 11 * 7, math.floor(4096 * scale))\n",
        "        self.fc2 = nn.Linear(math.floor(4096 * scale), math.floor(4096 * scale))\n",
        "        self.fc3 = nn.Linear(math.floor(4096 * scale), 6)\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.thresh(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.thresh(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "network = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssexJfPuicrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define network's loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(network.parameters(), lr = learnRate, momentum = momentumNum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4j_Yu2KnPLt",
        "colab_type": "code",
        "outputId": "34f80295-a0ff-49fe-cd20-91ca113ba526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "# Initialize weight of layers\n",
        "# takes in a module and applies the specified weight initialization\n",
        "def weights_init_rule(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model..\n",
        "    if classname.find('Linear') != -1:\n",
        "        # get the number of the inputs\n",
        "        # n = m.in_features\n",
        "        # y = 1.0/np.sqrt(n)\n",
        "        # m.weight.data.uniform_(-y, y)\n",
        "        # m.weight.data.normal_(0.0, y)\n",
        "        m.bias.data.fill_(0)\n",
        "        torch.nn.init.kaiming_uniform_(m.weight, \n",
        "                              a=0, \n",
        "                              mode='fan_in', \n",
        "                              nonlinearity='relu')\n",
        "\n",
        "network.apply(weights_init_rule)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(11, 265), stride=(4, 4), padding=(2, 2))\n",
              "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              "  (thresh): Threshold(threshold=0, value=1e-06)\n",
              "  (fc1): Linear(in_features=1232, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=6, bias=True)\n",
              "  (softmax): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av0A1Mkjiha_",
        "colab_type": "code",
        "outputId": "bbd93ef6-0e00-4ddf-8d61-72eae99e3ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "source": [
        "# scheduler = StepLR(optimizer, step_size= 1, gamma= 0.1)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(epochNum):  # loop over the dataset multiple times\n",
        "    print('Starting epoch: ' + str(epoch))\n",
        "    \n",
        "    running_loss = 0.0\n",
        "\n",
        "    for (inputs, labels) in trainloader:\n",
        "        # forward pass to get outputs\n",
        "        outputs = network(inputs)\n",
        "\n",
        "        # calculate loss between predicted and target\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # zero the parameter (weight) gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward + optimize only in training\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step() # Decay Learning Rate\n",
        "        \n",
        "        # update loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # epoch_loss = running_loss / data_lengths[phase]\n",
        "    # print('{} Loss: {}'.format(phase, epoch_loss))\n",
        "    print(str(running_loss))\n",
        "        \n",
        "          \n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "97.96128833293915\n",
            "Starting epoch: 1\n",
            "96.7361900806427\n",
            "Starting epoch: 2\n",
            "95.74933552742004\n",
            "Starting epoch: 3\n",
            "95.54054272174835\n",
            "Starting epoch: 4\n",
            "94.37058913707733\n",
            "Starting epoch: 5\n",
            "92.25618696212769\n",
            "Starting epoch: 6\n",
            "89.0634970664978\n",
            "Starting epoch: 7\n",
            "87.06785309314728\n",
            "Starting epoch: 8\n",
            "85.72022426128387\n",
            "Starting epoch: 9\n",
            "85.901526927948\n",
            "Starting epoch: 10\n",
            "83.98375928401947\n",
            "Starting epoch: 11\n",
            "82.43098735809326\n",
            "Starting epoch: 12\n",
            "82.77393519878387\n",
            "Starting epoch: 13\n",
            "82.24405777454376\n",
            "Starting epoch: 14\n",
            "80.45260053873062\n",
            "Starting epoch: 15\n",
            "79.53846335411072\n",
            "Starting epoch: 16\n",
            "79.36287987232208\n",
            "Starting epoch: 17\n",
            "78.88438832759857\n",
            "Starting epoch: 18\n",
            "76.65489792823792\n",
            "Starting epoch: 19\n",
            "78.69915866851807\n",
            "Starting epoch: 20\n",
            "76.35486829280853\n",
            "Starting epoch: 21\n",
            "75.85707640647888\n",
            "Starting epoch: 22\n",
            "76.96010506153107\n",
            "Starting epoch: 23\n",
            "75.12306898832321\n",
            "Starting epoch: 24\n",
            "73.48253130912781\n",
            "Starting epoch: 25\n",
            "75.012411236763\n",
            "Starting epoch: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYk5PnhyjfGI",
        "colab_type": "code",
        "outputId": "12c5140b-a875-4054-d2db-bb47228e3252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Testing the network on test images\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for (images, labels) in testloader:\n",
        "        outputs = network(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on test images: 51 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4VpEQ8Z0_DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}